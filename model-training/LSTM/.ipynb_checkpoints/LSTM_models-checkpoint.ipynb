{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1588538638645,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "YxrbPPfwDnq2",
    "outputId": "aab8744f-c8e6-4782-b117-369e7e910026"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1907,
     "status": "ok",
     "timestamp": 1588540623521,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "4HZ255UbDnry",
    "outputId": "883cf667-2874-4521-af3a-123c94644091"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hTFazuiDnr_"
   },
   "source": [
    "#  Modelling LSTM with GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17086,
     "status": "ok",
     "timestamp": 1588538626260,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "sVRzJIB6GXVh",
    "outputId": "5b3a774c-2e81-4fc5-95e2-f5ec4ca438bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      " 190103_StratifiedKFold_Retrained_Emmy.ipynb   dval.csv\n",
      "'Copy of BERT for Readmission.ipynb'\t       glove.6B.100d.txt\n",
      " dtest.csv\t\t\t\t       Hankerrank_practice.ipynb\n",
      " dtrain.csv\t\t\t\t       LSTM.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Learn how to import data from https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount = True)\n",
    "\n",
    "# there will be a prompt for authentication. Follow the link, click yes, and copy the token\n",
    "\n",
    "# get name of the files in folder\n",
    "!ls \"/content/gdrive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpEcZuYgEwgS"
   },
   "outputs": [],
   "source": [
    "filepath = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "dtrain = pd.read_csv(filepath+'dtrain.csv', index_col = 0)\n",
    "dval = pd.read_csv(filepath+'dval.csv', index_col = 0)\n",
    "dtest = pd.read_csv(filepath+'dtest.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiKub3HRDnsA"
   },
   "outputs": [],
   "source": [
    "#Creating training and test\n",
    "X_train, y_train = dtrain['TEXT'], dtrain['READMIT']\n",
    "X_val, y_val  = dval['TEXT'], dval['READMIT']\n",
    "X_test, y_test = dtest['TEXT'], dtest['READMIT']\n",
    "\n",
    "#Tokenize inputs\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train =tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "#Padding for same input length\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# maxlen = max([len(x) for x in X_train])\n",
    "maxlen = 350\n",
    "\n",
    "X_train = pad_sequences(X_train, padding = \"post\", maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test, padding = \"post\", maxlen = maxlen)\n",
    "X_val = pad_sequences(X_val, padding = \"post\", maxlen = maxlen)\n",
    "# Reading in GloVe embeddings\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open(filepath+'glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "# Creating embedding matrix with our words\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8506,
     "status": "ok",
     "timestamp": 1588540659282,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "sdYS-tenDnsB",
    "outputId": "1d922543-9584-45f6-f431-4cddced1e37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 350, 100)          6664600   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,781,977\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 6,664,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128, dropout_W = 0.3, dropout_U = 0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePjZNgWoDnsE"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516915,
     "status": "ok",
     "timestamp": 1588541168593,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "znm4q5kVLywo",
    "outputId": "7eafaa01-d340-4d28-fc75-3db03487b697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844/1844 [==============================] - 3s 2ms/step\n",
      "test loss, test acc: [0.521081499060426, 0.7776572704315186]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('test loss, test acc:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khxByn16L7f9"
   },
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1588538469139,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "at_vxhWlRQ0i",
    "outputId": "961d14b0-4857-430f-c6bb-535dc04b73c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1844, 1), (1844,))"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAvSjduuQiyC"
   },
   "outputs": [],
   "source": [
    "torch.save(model,filepath+'model_LSTM_GloVe.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y94eyyYNDnsI"
   },
   "source": [
    "# Modeling LSTM with no pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4219,
     "status": "ok",
     "timestamp": 1588538654359,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "OXI5AkNoN0tH",
    "outputId": "556eb549-158c-404d-840a-d4e13547b480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfekeYhvTXVe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1588538654360,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "FDCl40cCPAqL",
    "outputId": "e5bddced-eb10-40f6-96f6-21fca3243f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P4\n"
     ]
    }
   ],
   "source": [
    "#Check if CUDA is available\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7M9atWFNfLV"
   },
   "outputs": [],
   "source": [
    "UNK = \"<UNK>\"\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "def build_vocab(data, min_count=3, max_vocab=None):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences (list of strings)\n",
    "    \"\"\"\n",
    "    # keep track of the number of appearance of each word\n",
    "    word_count = Counter()\n",
    "    data = data.astype(str)\n",
    "    for i in range(len(data)):\n",
    "        sentence = re.sub('[\\\\(\\[:;*#.!?,\\'\\/\\])0-9]', ' ',data.iloc[i])\n",
    "        word_count.update(word_tokenize(sentence.lower()))\n",
    "    \n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return vocabulary, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AiALs73Nme0"
   },
   "outputs": [],
   "source": [
    "vocabulary, vocab_indices = build_vocab(dtrain['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcUoBXKgNqKz"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, vocab_index, data, label = 'READMIT'):\n",
    "        self.vocab_index = vocab_index\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        self.data['TEXT'].astype(str)\n",
    "        sentence = self.data['TEXT'].iloc[idx]\n",
    "      \n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "\n",
    "        token_indices = np.array([self.vocab_index[word] if word in self.vocab_index else self.vocab_index['<UNK>'] \n",
    "                                  for word in word_tokenize(sentence.lower())])\n",
    "     \n",
    "        return (torch.tensor(token_indices) , self.data['READMIT'].iloc[idx])\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=len(vocabulary)-1)\n",
    "\n",
    "    return torch.as_tensor(xx_pad), torch.as_tensor(x_lens), torch.LongTensor(yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NuedW7vNtrp"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "\n",
    "train_loader = DataLoader(LoadDataset(vocab_indices, dtrain),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          collate_fn = pad_collate)\n",
    "\n",
    "val_loader = DataLoader(LoadDataset(vocab_indices, dval),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)\n",
    "\n",
    "test_loader = DataLoader(LoadDataset(vocab_indices, dtest),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "se0logWUNwum"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, rnn='LSTM'):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn_fn = rnn\n",
    "        assert self.rnn_fn in ['GRU','LSTM']\n",
    "        self.rnn = getattr(nn, rnn)(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        _, last_hidden = self.rnn(pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False))\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            last_hidden = last_hidden[0]\n",
    "        out = self.fc(last_hidden.view(-1, self.hidden_dim))\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CYlwZO_N5hA"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "\n",
    "def train(model, train_loader=train_loader, val_loader=val_loader, num_epoch=10):\n",
    "    # Training steps\n",
    "    start_time = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate=0.001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=10**(-5))\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    best_acc = 0.\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        #Initialize\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (data, data_len, labels) in enumerate(train_loader):\n",
    "            data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "            outputs = model(data, data_len)\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = outputs.data.max(-1)[1]  \n",
    "            total += labels.size(0)\n",
    "            correct += torch.sum(pred ==labels).item()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        acc = correct/total\n",
    "        t_loss = total_loss/total\n",
    "        train_loss.append(t_loss)\n",
    "        train_acc.append(acc)\n",
    "        \n",
    "        print('Epoch: ',epoch)\n",
    "        print('Train set | Accuracy: {:6.4f} | Loss: {:6.4f}'.format(acc, t_loss))     \n",
    "    \n",
    "        # Evaluate after every epoch\n",
    "        #Reset the initialization\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        model.eval()\n",
    "        \n",
    "        predictions = []\n",
    "        truths = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, data_len, labels) in enumerate(val_loader):\n",
    "                data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "                outputs = model(data, data_len)\n",
    "                va_loss = loss_fn(outputs, labels)\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "            \n",
    "                total += labels.size(0)\n",
    "                correct += torch.sum(pred ==labels).item()\n",
    "                total_loss += va_loss.item()\n",
    "                \n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                \n",
    "            auc = roc_auc_score(truths, predictions)\n",
    "                \n",
    "                \n",
    "            v_acc = correct/total\n",
    "            v_loss = total_loss/total\n",
    "            val_loss.append(v_loss)\n",
    "            val_acc.append(v_acc)\n",
    "        \n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Validation set | Accuracy: {:6.4f} | AUC: {:4.2f} | Loss: {:4.2f} | time elapse: {:>9}'.format(\n",
    "                v_acc, auc, v_loss, elapse))\n",
    "            print('-'*10)\n",
    "            \n",
    "            if v_acc > best_acc:\n",
    "                best_acc = v_acc\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "    print('Best validation accuracy: {:6.4f}'.format(best_acc))\n",
    "    model.load_state_dict(best_model)     \n",
    "    return train_loss, train_acc, val_loss, val_acc, model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FpF3A-KOAMn"
   },
   "outputs": [],
   "source": [
    "LSTM_model = LSTMModel(100,2,len(vocabulary),128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862378,
     "status": "ok",
     "timestamp": 1588539869695,
     "user": {
      "displayName": "Emmy Phung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgalKrgNgMyAd0ON9QYL1eL_FUcvZLcS1zH4dUp=s64",
      "userId": "06403056978504730323"
     },
     "user_tz": 240
    },
    "id": "Opjt-DzqOJxh",
    "outputId": "1defa16b-7e25-4602-edb3-73614f354e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0085\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:01:26\n",
      "----------\n",
      "Epoch:  1\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:02:52\n",
      "----------\n",
      "Epoch:  2\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:04:16\n",
      "----------\n",
      "Epoch:  3\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0085\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:05:42\n",
      "----------\n",
      "Epoch:  4\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:07:07\n",
      "----------\n",
      "Epoch:  5\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:08:32\n",
      "----------\n",
      "Epoch:  6\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:10:00\n",
      "----------\n",
      "Epoch:  7\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0085\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:11:28\n",
      "----------\n",
      "Epoch:  8\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0085\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:12:55\n",
      "----------\n",
      "Epoch:  9\n",
      "Train set | Accuracy: 0.7767 | Loss: 0.0084\n",
      "Validation set | Accuracy: 0.7766 | AUC: 0.50 | Loss: 0.01 | time elapse:  00:14:22\n",
      "----------\n",
      "Best validation accuracy: 0.7766\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2020)\n",
    "train_loss_LSTM, train_acc_LSTM, val_loss_LSTM, val_acc_LSTM, model_LSTM = train(LSTM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rrby1eWCOMGA"
   },
   "outputs": [],
   "source": [
    "#Evaluate the model on the test set.\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    total =0.\n",
    "    correct = 0.\n",
    "    y_pred =[]\n",
    "    y_true= []\n",
    "    y_proba = []\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        for i, (data, data_len, labels) in enumerate(test_loader):\n",
    "            data, data_len = data.to(device), data_len.to(device)\n",
    "            outputs = model_LSTM(data, data_len)\n",
    "            #pred = outputs.data.max(-1)[1]\n",
    "            total += labels.size(0)\n",
    "  \n",
    "\n",
    "\n",
    "            label_cpu = labels.squeeze().numpy()\n",
    "                \n",
    "            #predict probability\n",
    "          \n",
    "            proba = F.softmax(outputs).to('cpu').numpy()[:,1]\n",
    "            \n",
    "            #predict label\n",
    "            pred = outputs.data.max(-1)[1].to('cpu').numpy()\n",
    "        \n",
    "            \n",
    "            correct += float(sum((pred ==label_cpu)))\n",
    "          \n",
    "            \n",
    "            y_proba += list(proba)  #use for ROC and AUC\n",
    "            y_pred += list(pred)    #use for confusion matrix\n",
    "            y_true += list(label_cpu) #use for all\n",
    "        \n",
    "          \n",
    "        v_auc = roc_auc_score(y_true, y_proba)\n",
    "        v_acc = correct/total\n",
    "\n",
    "\n",
    "    print('Test set | Accuracy: {:6.4f}'.format(v_acc))\n",
    "    print('Test set | AUC: {:6.4f}'.format(v_auc))\n",
    "\n",
    "    return y_true, y_pred, y_proba #y_proba_class0\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWvKqBRYQYkI"
   },
   "outputs": [],
   "source": [
    "torch.save(model_LSTM,filepath+'model_LSTM_noGloVe.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of BERT for Readmission.ipynb",
   "provenance": [
    {
     "file_id": "1k8Ul4xF0MQgojhowUZLrLHrb20peiAJ_",
     "timestamp": 1588534930032
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
